{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drain.model import Drain,Node,LogCluster\n",
    "from drain.optimizer import Optimizer\n",
    "from drain.plotter import createPlot\n",
    "from drain.partition import Partition\n",
    "from utils.data_utils import *\n",
    "import unsupervised.model as unsupervised_model\n",
    "# import unsupervised.model as unsupervised_model\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 32\n",
    "batch_size = 2048\n",
    "input_size = 1\n",
    "window_size = 10\n",
    "num_layers = 2\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "logPath = 'D:\\\\毕业设计\\\\loghub\\\\HDFS_1\\\\HDFS.log'\n",
    "parsed_result = '.\\\\data\\\\parser\\\\log_item_to_label.csv'\n",
    "cluster_result = '.\\\\data\\\\parser\\\\'\n",
    "# partition\n",
    "partition_output = '.\\\\data\\\\lstm\\\\dataset\\\\'\n",
    "instance_file = 'instance.csv'\n",
    "label_file = '.\\\\data\\\\partition\\\\anormaly_label.csv'\n",
    "normal_output = 'normal.csv'\n",
    "abnormal_output = 'abnormal.csv'\n",
    "\n",
    "#lstm dataset\n",
    "lstm_dataset = '.\\\\data\\\\lstm\\\\dataset\\\\'\n",
    "unsupervised_train = 'train.csv'\n",
    "unsupervised_test_normal = 'normal.csv'\n",
    "unsupervised_test_abnormal = 'abnormal.csv'\n",
    "\n",
    "predicted_input = 'unsupervised_input.csv'\n",
    "predicted_normal_output = 'unsupervised_normal_output.csv'\n",
    "predicted_abnormal_output = 'unsupervised_abnormal_output.csv'\n",
    "supervised_test = 'supervised_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log():\n",
    "\n",
    "    rex = ['blk_(|-)[0-9]+', '(/|)([0-9]+\\.){3}[0-9]+(:[0-9]+|)(:|)']\n",
    "    removeCol = [0,1,2]\n",
    "    myParser = Drain(rex=rex,removeCol=removeCol,st=0.4)\n",
    "    myParser.fit(isReconstruct=True,inputFile=logPath,outputFile=parsed_result)\n",
    "\n",
    "    myParser.save(savePath=cluster_result)\n",
    "\n",
    "'''\n",
    "partition phase\n",
    "'''\n",
    "def partition():\n",
    "\n",
    "    partition = Partition(outputFileDir=partition_output,log_item_to_event_id_file=parsed_result,instances_file_path=instance_file,label_file_path=label_file,normal_output=normal_output,abnormal_output=abnormal_output)\n",
    "    partition.partition_by_file()\n",
    "    partition.map_log_seq_to_label()\n",
    "\n",
    "    split_data(input_dir=partition_output,output_dir=lstm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model'\n",
    "version = '0.1'\n",
    "input_size = 1\n",
    "model_usl_name = 'type={}_version={}'.format('unsupervised',version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model type=unsupervised_version=0.1 success.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = unsupervised_model.Model(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "if os.path.exists(model_dir + '/' + model_usl_name + '.pt'):\n",
    "    model.load_state_dict(torch.load(model_dir + '/' + model_usl_name + '.pt'))\n",
    "    print('loading model {} success.'.format(model_usl_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\data\\\\lstm\\\\dataset\\\\train.csv'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_dataset + unsupervised_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 100%|█████████████████████████████████████████████████████████████| 5582/5582 [00:00<00:00, 19583.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset\\train.csv): 5582\n",
      "Number of seqs(.\\data\\lstm\\dataset\\train.csv): 114877\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=31)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "train_dataset = generate_train_data(lstm_dataset + unsupervised_train)\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], train_loss: 0.4358\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-4385d0085a82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0munsupervised_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\python_workspace\\jupyter_notebook\\毕业设计\\dev\\end_to_end\\unsupervised\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, current_epoch, num_epochs, window_size, input_size)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Loop over the dataset multiple times\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "unsupervised_model.train(model, dataloader, criterion, optimizer, current_epoch=0, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(model.state_dict(), model_dir + '/' + model_usl_name + '.pt')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\\data\\lstm\\dataset\\normal.csv: 100%|██████████████████████████████████████████| 14176/14176 [00:01<00:00, 8591.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset\\normal.csv): 14176\n",
      "Number of seqs(.\\data\\lstm\\dataset\\normal.csv): 269279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\\data\\lstm\\dataset\\abnormal.csv: 100%|█████████████████████████████████████████| 4124/4124 [00:00<00:00, 11552.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset\\abnormal.csv): 4124\n",
      "Number of seqs(.\\data\\lstm\\dataset\\abnormal.csv): 88592\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "batch_size = 20000\n",
    "test_normal_session, test_normal_dataset, normal_block = generate_predicted_data(\n",
    "    lstm_dataset + unsupervised_test_normal, window_size)\n",
    "normal_dataloader = DataLoader(test_normal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_abnormal_session, test_abnormal_dataset, abnormal_block = generate_predicted_data(\n",
    "    lstm_dataset + unsupervised_test_abnormal, window_size)\n",
    "abnormal_dataloader = DataLoader(test_abnormal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\\data\\lstm\\dataset\\no_dup_normal.csv: 100%|██████████████████████████████████| 14176/14176 [00:01<00:00, 11101.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset\\no_dup_normal.csv): 14176\n",
      "Number of seqs(.\\data\\lstm\\dataset\\no_dup_normal.csv): 269279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\\data\\lstm\\dataset\\no_dup_abnormal.csv: 100%|██████████████████████████████████| 4124/4124 [00:00<00:00, 10938.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset\\no_dup_abnormal.csv): 4124\n",
      "Number of seqs(.\\data\\lstm\\dataset\\no_dup_abnormal.csv): 88592\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "batch_size = 20000\n",
    "test_normal_session, test_normal_dataset, normal_block = generate_predicted_data(\n",
    "    lstm_dataset + 'no_dup_normal.csv', window_size)\n",
    "normal_dataloader = DataLoader(test_normal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_abnormal_session, test_abnormal_dataset, abnormal_block = generate_predicted_data(\n",
    "    lstm_dataset + 'no_dup_abnormal.csv', window_size)\n",
    "abnormal_dataloader = DataLoader(test_abnormal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unsupervised.predictor as unsupervised_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 5it [00:24,  4.80s/it]\n"
     ]
    }
   ],
   "source": [
    "re = unsupervised_predictor.predict(model, abnormal_dataloader,test_abnormal_session,10, window_size,ts=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.count(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "loading data: 0it [00:00, ?it/s]\u001b[A\n",
      "loading data: 1it [00:04,  4.76s/it]\u001b[A\n",
      "loading data: 2it [00:09,  4.69s/it]\u001b[A\n",
      "loading data: 3it [00:13,  4.68s/it]\u001b[A\n",
      "loading data: 4it [00:18,  4.71s/it]\u001b[A\n",
      "loading data: 5it [00:23,  4.83s/it]\u001b[A\n",
      "loading data: 6it [00:29,  5.01s/it]\u001b[A\n",
      "loading data: 7it [00:34,  5.07s/it]\u001b[A\n",
      "loading data: 8it [00:39,  4.96s/it]\u001b[A\n",
      "loading data: 9it [00:44,  4.94s/it]\u001b[A\n",
      "loading data: 10it [00:48,  4.79s/it]\u001b[A\n",
      "loading data: 11it [00:53,  4.78s/it]\u001b[A\n",
      "loading data: 12it [00:58,  4.81s/it]\u001b[A\n",
      "loading data: 13it [01:02,  4.77s/it]\u001b[A\n",
      "loading data: 14it [01:04,  4.64s/it]\u001b[A\n",
      "\n",
      "loading data: 0it [00:00, ?it/s]\u001b[A\n",
      "loading data: 1it [00:04,  4.87s/it]\u001b[A\n",
      "loading data: 2it [00:09,  4.79s/it]\u001b[A\n",
      "loading data: 3it [00:15,  5.26s/it]\u001b[A\n",
      "loading data: 4it [00:20,  5.06s/it]\u001b[A\n",
      "loading data: 5it [00:23,  4.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 88.259s\n",
      "false positive (FP): 862, false negative (FN): 698, Precision: 79.897%, Recall: 83.075%, F1-measure: 81.455%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_normal_result, test_abnormal_result = unsupervised_predictor.count_metries(model, normal_dataloader, abnormal_dataloader,\n",
    "                                                        test_normal_session, test_abnormal_session,\n",
    "                                                        10, window_size,ts=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 14it [01:12,  5.19s/it]\n",
      "loading data: 5it [00:21,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 94.541s\n",
      "false positive (FP): 396, false negative (FN): 1540, Precision: 86.711%, Recall: 62.658%, F1-measure: 72.748%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_normal_result, test_abnormal_result = unsupervised_predictor.count_metries(model, normal_dataloader, abnormal_dataloader,\n",
    "                                                        test_normal_session, test_abnormal_session,\n",
    "                                                        10, window_size,ts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsupervised_input.csv'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ".\\data\\lstm\\dataset\\unsupervised_input.csv:   0%|                                             | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      ".\\data\\lstm\\dataset\\unsupervised_input.csv:  26%|████████                       | 1303/5000 [00:00<00:00, 13028.74it/s]\u001b[A\n",
      ".\\data\\lstm\\dataset\\unsupervised_input.csv:  51%|███████████████▋               | 2539/5000 [00:00<00:00, 12780.95it/s]\u001b[A\n",
      ".\\data\\lstm\\dataset\\unsupervised_input.csv:  76%|███████████████████████▍       | 3787/5000 [00:00<00:00, 12689.12it/s]\u001b[A\n",
      ".\\data\\lstm\\dataset\\unsupervised_input.csv: 100%|████████████████████████████████| 5000/5000 [00:00<00:00, 6385.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset\\unsupervised_input.csv): 5000\n",
      "Number of seqs(.\\data\\lstm\\dataset\\unsupervised_input.csv): 92307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sessions, dataset, block_to_seqs = generate_predicted_data(lstm_dataset+predicted_input,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20000\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "loading data: 0it [00:00, ?it/s]\u001b[A\n",
      "loading data: 1it [00:05,  5.22s/it]\u001b[A\n",
      "loading data: 2it [00:10,  5.27s/it]\u001b[A\n",
      "loading data: 3it [00:16,  5.37s/it]\u001b[A\n",
      "loading data: 4it [00:21,  5.46s/it]\u001b[A\n",
      "loading data: 5it [00:25,  5.04s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "normal_result = unsupervised_predictor.predict(model, dataloader,sessions,10, window_size,ts=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(result):\n",
    "    TN = result[:3000].count(False)\n",
    "    FN = result[3000:].count(False)\n",
    "    print('TN:{} FN:{}'.format(TN,FN))\n",
    "    print('Negative Precision:',TN/(TN+FN))\n",
    "    TP = result[3000:].count(True)\n",
    "    FP = result[:3000].count(True)\n",
    "    print('TP:{} FP:{}'.format(TP,FP))\n",
    "    print('Positive Precision:',TP/(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:2647 FN:140\n",
      "Negative Precision: 0.9497667743092931\n",
      "TP:1860 FP:353\n",
      "Positive Precision: 0.8404880253050158\n"
     ]
    }
   ],
   "source": [
    "show_result(normal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 57it [00:13,  4.28it/s]\n"
     ]
    }
   ],
   "source": [
    "abnormal_result = unsupervised_predictor.predict(model, dataloader,sessions,10, window_size,ts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:5 FN:7\n",
      "Negative Precision: 0.4166666666666667\n",
      "TP:1993 FP:2995\n",
      "Positive Precision: 0.3995589414595028\n"
     ]
    }
   ],
   "source": [
    "show_result(abnormal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(lstm_dataset+predicted_normal_output,'w')\n",
    "f.write('BlockId,EventSequence\\n')\n",
    "for i,label in enumerate(normal_result):\n",
    "    if label==False:\n",
    "        f.write(block_to_seqs[i][0]+',\"'+str(block_to_seqs[i][1])+'\"\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(lstm_dataset+predicted_abnormal_output,'w')\n",
    "f.write('BlockId,EventSequence\\n')\n",
    "for i,label in enumerate(abnormal_result):\n",
    "    if label:\n",
    "        f.write(block_to_seqs[i][0]+',\"'+str(block_to_seqs[i][1])+'\"\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\data\\\\lstm\\\\dataset\\\\unsupervised_normal_output.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_dataset+predicted_normal_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 100%|████████████████████████████████████████████████████████████| 2787/2787 [00:00<00:00, 186112.26it/s]\n",
      "loading data: 100%|████████████████████████████████████████████████████████████| 1328/1328 [00:00<00:00, 166046.67it/s]\n",
      "normal:: 100%|█████████████████████████████████████████████████████████████████████| 2786/2786 [01:09<00:00, 39.82it/s]\n",
      "abnormal:: 100%|███████████████████████████████████████████████████████████████████| 1324/1324 [00:33<00:00, 39.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset\\): 4110\n",
      "Number of normal sessions: 2786\n",
      "Number of abnormal sessions: 1324\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset=generate_bert_data(lstm_dataset,predicted_normal_output,predicted_abnormal_output,\"./data/lstm/bert_cache.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervised.model as supervised_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = supervised_model.Model(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sl_name = 'type={}_version={}'.format('supervised',version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_dir + '/' + model_sl_name + '.pt'):\n",
    "    print('loading model {} success.'.format(model_sl_name))\n",
    "    model.load_state_dict(torch.load(model_dir + '/' + model_name + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], train_loss: 0.0735\n",
      "Epoch [2/50], train_loss: 0.0711\n",
      "Epoch [3/50], train_loss: 0.0734\n",
      "Epoch [4/50], train_loss: 0.0697\n",
      "Epoch [5/50], train_loss: 0.0715\n",
      "Epoch [6/50], train_loss: 0.0770\n",
      "Epoch [7/50], train_loss: 0.0797\n",
      "Epoch [8/50], train_loss: 0.0651\n",
      "Epoch [9/50], train_loss: 0.0617\n",
      "Epoch [10/50], train_loss: 0.0633\n",
      "Epoch [11/50], train_loss: 0.0622\n",
      "Epoch [12/50], train_loss: 0.0681\n",
      "Epoch [13/50], train_loss: 0.0932\n",
      "Epoch [14/50], train_loss: 0.1097\n",
      "Epoch [15/50], train_loss: 0.0853\n",
      "Epoch [16/50], train_loss: 0.0812\n",
      "Epoch [17/50], train_loss: 0.0833\n",
      "Epoch [18/50], train_loss: 0.0690\n",
      "Epoch [19/50], train_loss: 0.0655\n",
      "Epoch [20/50], train_loss: 0.0703\n",
      "Epoch [21/50], train_loss: 0.0736\n",
      "Epoch [22/50], train_loss: 0.0646\n",
      "Epoch [23/50], train_loss: 0.0844\n",
      "Epoch [24/50], train_loss: 0.0883\n",
      "Epoch [25/50], train_loss: 0.1821\n",
      "Epoch [26/50], train_loss: 0.1909\n",
      "Epoch [27/50], train_loss: 0.1072\n",
      "Epoch [28/50], train_loss: 0.0690\n",
      "Epoch [29/50], train_loss: 0.0622\n",
      "Epoch [30/50], train_loss: 0.0593\n",
      "Epoch [31/50], train_loss: 0.0652\n",
      "Epoch [32/50], train_loss: 0.0843\n",
      "Epoch [33/50], train_loss: 0.0610\n",
      "Epoch [34/50], train_loss: 0.0584\n",
      "Epoch [35/50], train_loss: 0.0557\n",
      "Epoch [36/50], train_loss: 0.0551\n",
      "Epoch [37/50], train_loss: 0.0700\n",
      "Epoch [38/50], train_loss: 0.1003\n",
      "Epoch [39/50], train_loss: 0.0688\n",
      "Epoch [40/50], train_loss: 0.0672\n",
      "Epoch [41/50], train_loss: 0.0661\n",
      "Epoch [42/50], train_loss: 0.0633\n",
      "Epoch [43/50], train_loss: 0.0596\n",
      "Epoch [44/50], train_loss: 0.0587\n",
      "Epoch [45/50], train_loss: 0.0821\n",
      "Epoch [46/50], train_loss: 0.0726\n",
      "Epoch [47/50], train_loss: 0.0643\n",
      "Epoch [48/50], train_loss: 0.0546\n",
      "Epoch [49/50], train_loss: 0.0581\n",
      "Epoch [50/50], train_loss: 0.1105\n",
      "elapsed_time: 79.459s\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "supervised_model.train(model,train_dataloader,criterion,optimizer,current_epoch=0,num_epochs=50,input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def accuracy(y_pred, y_true):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    pred = np.argmax(y_pred.cpu().numpy(),1)\n",
    "    for i,val in enumerate(pred):\n",
    "        if val == 0:\n",
    "            if y_true[i]==0:\n",
    "                TN +=1\n",
    "            else:\n",
    "                FN +=1\n",
    "        else:\n",
    "            if y_true[i]==1:\n",
    "                TP+=1\n",
    "            else:\n",
    "                FP+=1\n",
    "    return TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model,data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        for step, (seq, label) in enumerate(data):\n",
    "            seq = seq.clone().detach().view(-1, seq.shape[1], input_size).to(device)\n",
    "            test_output = model(seq.to(device))\n",
    "            if step == 0:\n",
    "                output = test_output\n",
    "                labels = label\n",
    "            else:\n",
    "                labels = torch.cat([labels, label], 0)\n",
    "                output = torch.cat([output, test_output], 0)\n",
    "            epoch_loss += criterion(test_output, label.to(device)).data\n",
    "        TP,TN,FP,FN = accuracy(output, labels)\n",
    "        epoch_accuracy = (TP+TN)/(FP+FN+TP+TN)\n",
    "        epoch_loss = epoch_loss / len(data)\n",
    "        print('TN:{} FN:{}'.format(TN,FN))\n",
    "        print('Negative Precision:',round(TN/(TN+FN),3))\n",
    "        print('TP:{} FP:{}'.format(TP,FP))\n",
    "        print('Positive Precision:',round(TP/(TP+FP),3))\n",
    "        print('loss: ', round(epoch_loss.item(), 3), 'accuracy: ', round(epoch_accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:1643 FN:52\n",
      "Negative Precision: 0.969\n",
      "TP:758 FP:13\n",
      "Positive Precision: 0.983\n",
      "loss:  0.088 accuracy:  0.974\n"
     ]
    }
   ],
   "source": [
    "predict_result(model,train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:1105 FN:38\n",
      "Negative Precision: 0.967\n",
      "TP:476 FP:25\n",
      "Positive Precision: 0.95\n",
      "loss:  0.134 accuracy:  0.962\n"
     ]
    }
   ],
   "source": [
    "predict_result(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_input_normal = 'supervised_input_normal.csv'\n",
    "supervised_input_abnormal = 'supervised_input_abnormal.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 100%|████████████████████████████████████████████████████████████| 4999/4999 [00:00<00:00, 277764.43it/s]\n",
      "loading data: 100%|████████████████████████████████████████████████████████████| 2124/2124 [00:00<00:00, 212223.11it/s]\n",
      "normal:: 100%|█████████████████████████████████████████████████████████████████████| 4977/4977 [01:57<00:00, 42.21it/s]\n",
      "abnormal:: 100%|███████████████████████████████████████████████████████████████████| 2115/2115 [00:52<00:00, 40.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset\\): 7092\n",
      "Number of normal sessions: 4977\n",
      "Number of abnormal sessions: 2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset1,test_dataset2 =generate_bert_data(lstm_dataset,supervised_input_normal,supervised_input_abnormal,\"./data/lstm/bert_cache.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader1 = DataLoader(test_dataset1, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader2 = DataLoader(test_dataset2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:2757 FN:201\n",
      "Negative Precision: 0.932\n",
      "TP:1063 FP:234\n",
      "Positive Precision: 0.82\n",
      "loss:  0.416 accuracy:  0.898\n"
     ]
    }
   ],
   "source": [
    "predict_result(model,test_dataloader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:1800 FN:127\n",
      "Negative Precision: 0.934\n",
      "TP:724 FP:186\n",
      "Positive Precision: 0.796\n",
      "loss:  0.456 accuracy:  0.89\n"
     ]
    }
   ],
   "source": [
    "predict_result(model,test_dataloader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('cuda_pytorch': conda)",
   "language": "python",
   "name": "python36764bitcudapytorchconda3e33319a1fef4dc990a9d2f171216946"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
