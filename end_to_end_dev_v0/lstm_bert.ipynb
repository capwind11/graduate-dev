{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_epochs = 20\n",
    "batch_size = 50\n",
    "input_size = 768\n",
    "model_dir = 'model'\n",
    "window_size = 10\n",
    "num_layers = 2\n",
    "hidden_size = 64\n",
    "file_dir = 'data_supervised'\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_data(file_dir,bert_cache_path):\n",
    "    eventId_to_bert = torch.load(bert_cache_path)\n",
    "    padding = torch.zeros_like(eventId_to_bert[5][1][0])\n",
    "    eventId_to_bert[0] = [[], [padding]]\n",
    "    sessions = []\n",
    "    labels = []\n",
    "    max_len = 50\n",
    "    normal_data = set()\n",
    "    abnormal_data = set()\n",
    "    data = pd.read_csv('data/lstm/dataset/train.csv', engine='c', na_filter=False, memory_map=True)\n",
    "    blockId_list = data['BlockId'].tolist()\n",
    "    seqs = data['EventSequence'].apply(literal_eval).tolist()\n",
    "    for line in tqdm(seqs, \"loading data\"):\n",
    "        if len(line) > 50:\n",
    "            continue\n",
    "        normal_data.add(tuple(line))\n",
    "    data = pd.read_csv('data/lstm/dataset/abnormal.csv', engine='c', na_filter=False, memory_map=True)\n",
    "    blockId_list = data['BlockId'].tolist()\n",
    "    seqs = data['EventSequence'].apply(literal_eval).tolist()\n",
    "    for line in tqdm(seqs, \"loading data\"):\n",
    "        if len(line) > 50:\n",
    "            continue\n",
    "        abnormal_data.add(tuple(line))\n",
    "    for line in tqdm(normal_data, \"normal:\"):\n",
    "        line = list(line) + [0] * (max_len - len(line))\n",
    "        bert_input = []\n",
    "        for id in line:\n",
    "            bert_input.append(eventId_to_bert[id][1][0].cpu().numpy())\n",
    "        sessions.append(tuple(bert_input))\n",
    "        labels.append(0)\n",
    "    for line in tqdm(abnormal_data, \"abnormal:\"):\n",
    "        line = list(line) + [0] * (max_len - len(line))\n",
    "        bert_input = []\n",
    "        for id in line:\n",
    "            bert_input.append(eventId_to_bert[id][1][0].cpu().numpy())\n",
    "        sessions.append(tuple(bert_input))\n",
    "        labels.append(1)\n",
    "\n",
    "    print('Number of sessions({}): {}'.format(file_dir, len(sessions)))\n",
    "    print('Number of normal sessions: {}'.format(len(normal_data)))\n",
    "    print('Number of abnormal sessions: {}'.format(len(abnormal_data)))\n",
    "    train_x, test_x, train_y, test_y = train_test_split(sessions, labels, test_size=0.3)\n",
    "    train_data = TensorDataset(torch.tensor(train_x, dtype=torch.float), torch.tensor(train_y))\n",
    "    # train_data = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_data = TensorDataset(torch.tensor(test_x, dtype=torch.float), torch.tensor(test_y))\n",
    "    # test_data = DataLoader(test_data, batch_size=batch_size)\n",
    "    return train_data, test_data, train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 100%|████████████████████████████████████████████████████████████| 5582/5582 [00:00<00:00, 278943.98it/s]\n",
      "loading data: 100%|██████████████████████████████████████████████████████████| 16838/16838 [00:00<00:00, 244075.35it/s]\n",
      "normal:: 100%|███████████████████████████████████████████████████████████████████████| 909/909 [00:19<00:00, 45.79it/s]\n",
      "abnormal:: 100%|███████████████████████████████████████████████████████████████████| 4111/4111 [01:22<00:00, 49.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(data/lstm/dataset/): 5020\n",
      "Number of normal sessions: 909\n",
      "Number of abnormal sessions: 4111\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_x, test_x, train_y, test_y =generate_bert_data(\"data/lstm/dataset/\",\"./data/lstm/bert_cache.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_data = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_size, num_keys)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(2*self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloader,criterion,optimizer,current_epoch=0,num_epochs=10,input_size=1):\n",
    "    total_step = len(dataloader)\n",
    "    start_time = time.time()\n",
    "    for epoch in range(current_epoch,current_epoch+num_epochs):  # Loop over the dataset multiple times\n",
    "        train_loss = 0\n",
    "        for step, (seq, label) in enumerate(dataloader):\n",
    "            # Forward pass\n",
    "            seq = seq.clone().detach().view(-1, seq.shape[1], input_size).to(device)\n",
    "            output = model(seq)\n",
    "            loss = criterion(output, label.to(device))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            # writer.add_graph(model, seq)\n",
    "        print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, current_epoch+num_epochs, train_loss / total_step))\n",
    "        # writer.add_scalar('train_loss', train_loss / total_step, epoch + 1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed_time: {:.3f}s'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,train_data,criterion,optimizer,current_epoch=0,num_epochs=10,input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        for step, (seq, label) in enumerate(train_data):\n",
    "            seq = seq.clone().detach().view(-1, seq.shape[1], input_size).to(device)\n",
    "            test_output = model(seq.to(device))\n",
    "            if step == 0:\n",
    "                output = test_output\n",
    "                labels = label\n",
    "            else:\n",
    "                labels = torch.cat([labels, label], 0)\n",
    "                output = torch.cat([output, test_output], 0)\n",
    "            epoch_loss += criterion(test_output, label.to(device)).data\n",
    "        epoch_accuracy = accuracy(output, labels)\n",
    "        epoch_loss = epoch_loss / len(train_data)\n",
    "        print('loss: ', round(epoch_loss.item(), 3), 'accuracy: ', round(epoch_accuracy.item(), 3))\n",
    "        epoch_loss = 0\n",
    "        for step, (seq, label) in enumerate(test_data):\n",
    "            seq = seq.clone().detach().view(-1, seq.shape[1], input_size).to(device)\n",
    "            test_output = model(seq.to(device))\n",
    "            if step == 0:\n",
    "                output = test_output\n",
    "                labels = label\n",
    "            else:\n",
    "                labels = torch.cat([labels, label], 0)\n",
    "                output = torch.cat([output, test_output], 0)\n",
    "            epoch_loss += criterion(test_output, label.to(device)).data\n",
    "        epoch_accuracy = accuracy(output, labels)\n",
    "        epoch_loss = epoch_loss / len(train_data)\n",
    "        print('test_loss: ', round(epoch_loss.item(), 3), 'test_accuracy: ', round(epoch_accuracy.item(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('cuda_pytorch': conda)",
   "language": "python",
   "name": "python36764bitcudapytorchconda3e33319a1fef4dc990a9d2f171216946"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
