{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drain.model import Drain,Node,LogCluster\n",
    "from drain.optimizer import Optimizer\n",
    "from drain.plotter import createPlot\n",
    "from drain.partition import Partition\n",
    "from utils.data_utils import *\n",
    "import unsupervised.model as unsupervised_model\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 31\n",
    "batch_size = 2048\n",
    "input_size = 1\n",
    "window_size = 10\n",
    "num_layers = 2\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logPath = 'D:\\\\毕业设计\\\\loghub\\\\HDFS_1\\\\HDFS.log'\n",
    "parsed_result = '.\\\\data\\\\parser\\\\log_item_to_label.csv'\n",
    "cluster_result = '.\\\\data\\\\parser\\\\'\n",
    "# partition\n",
    "partition_output = '.\\\\data\\\\lstm\\\\dataset_official\\\\'\n",
    "instance_file = 'instance.csv'\n",
    "label_file = '.\\\\data\\\\partition\\\\anormaly_label.csv'\n",
    "normal_output = 'normal.csv'\n",
    "abnormal_output = 'abnormal.csv'\n",
    "\n",
    "#lstm dataset\n",
    "lstm_dataset = '.\\\\data\\\\lstm\\\\dataset_official\\\\'\n",
    "unsupervised_train = 'train.csv'\n",
    "unsupervised_test_normal = 'normal.csv'\n",
    "unsupervised_test_abnormal = 'abnormal.csv'\n",
    "\n",
    "predicted_input = 'unsupervised_input.csv'\n",
    "predicted_normal_output = 'unsupervised_normal_output.csv'\n",
    "predicted_abnormal_output = 'unsupervised_abnormal_output.csv'\n",
    "supervised_test = 'supervised_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log():\n",
    "\n",
    "    rex = ['blk_(|-)[0-9]+', '(/|)([0-9]+\\.){3}[0-9]+(:[0-9]+|)(:|)']\n",
    "    removeCol = [0,1,2]\n",
    "    myParser = Drain(rex=rex,removeCol=removeCol,st=0.4)\n",
    "    myParser.fit(isReconstruct=True,inputFile=logPath,outputFile=parsed_result)\n",
    "\n",
    "    myParser.save(savePath=cluster_result)\n",
    "\n",
    "'''\n",
    "partition phase\n",
    "'''\n",
    "def partition():\n",
    "\n",
    "    partition = Partition(outputFileDir=partition_output,log_item_to_event_id_file=parsed_result,instances_file_path=instance_file,label_file_path=label_file,normal_output=normal_output,abnormal_output=abnormal_output)\n",
    "    partition.partition_by_file()\n",
    "    partition.map_log_seq_to_label()\n",
    "\n",
    "    split_data(input_dir=partition_output,output_dir=lstm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model'\n",
    "version = '0.1'\n",
    "input_size = 1\n",
    "model_usl_name = 'dev_v1.2_batch_size=2048_epoch=300'\n",
    "# model_usl_name = 'type={}_version={}'.format('official_unsupervised',version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unsupervised_model.Model(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model dev_v1.2_batch_size=2048_epoch=300 success.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(model_dir + '/' + model_usl_name + '.pt'):\n",
    "    model.load_state_dict(torch.load(model_dir + '/' + model_usl_name + '.pt'))\n",
    "    print('loading model {} success.'.format(model_usl_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lstm): LSTM(1, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\data\\\\lstm\\\\dataset_official\\\\train.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_dataset + unsupervised_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 100%|█████████████████████████████████████████████████████████████| 4855/4855 [00:00<00:00, 24651.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset_official\\train.csv): 4855\n",
      "Number of seqs(.\\data\\lstm\\dataset_official\\train.csv): 99980\n"
     ]
    }
   ],
   "source": [
    "train_dataset = generate_train_data(lstm_dataset + unsupervised_train)\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5., 11.,  9., 11.,  9., 11.,  9., 26., 26., 26.],\n",
       "         [11.,  9., 11.,  9., 11.,  9., 26., 26., 26., 23.],\n",
       "         [ 9., 11.,  9., 11.,  9., 26., 26., 26., 23., 23.],\n",
       "         [11.,  9., 11.,  9., 26., 26., 26., 23., 23., 23.],\n",
       "         [ 9., 11.,  9., 26., 26., 26., 23., 23., 23., 21.],\n",
       "         [11.,  9., 26., 26., 26., 23., 23., 23., 21., 21.],\n",
       "         [ 9., 26., 26., 26., 23., 23., 23., 21., 21., 21.],\n",
       "         [ 0.,  5., 22.,  5.,  5., 11.,  9., 11.,  9., 11.],\n",
       "         [ 5., 22.,  5.,  5., 11.,  9., 11.,  9., 11.,  9.],\n",
       "         [22.,  5.,  5., 11.,  9., 11.,  9., 11.,  9., 26.],\n",
       "         [ 5.,  5., 11.,  9., 11.,  9., 11.,  9., 26., 26.],\n",
       "         [ 5., 11.,  9., 11.,  9., 11.,  9., 26., 26., 26.],\n",
       "         [11.,  9., 11.,  9., 11.,  9., 26., 26., 26., 23.],\n",
       "         [ 9., 11.,  9., 11.,  9., 26., 26., 26., 23., 23.],\n",
       "         [11.,  9., 11.,  9., 26., 26., 26., 23., 23., 23.],\n",
       "         [ 9., 11.,  9., 26., 26., 26., 23., 23., 23., 21.],\n",
       "         [11.,  9., 26., 26., 26., 23., 23., 23., 21., 21.],\n",
       "         [ 9., 26., 26., 26., 23., 23., 23., 21., 21., 21.],\n",
       "         [ 0.,  5., 22.,  5.,  5., 11.,  9., 11.,  9., 11.],\n",
       "         [ 5., 22.,  5.,  5., 11.,  9., 11.,  9., 11.,  9.]]),\n",
       " tensor([23, 23, 23, 21, 21, 21, 30,  9, 26, 26, 26, 23, 23, 23, 21, 21, 21, 30,\n",
       "          9, 26]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at C:/w/1/s/tmp_conda_3.6_095855/conda/conda-bld/pytorch_1579082406639/work/aten/src\\THC/generic/THCTensorMath.cu:26",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e96ca5c9af4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0munsupervised_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\python_workspace\\jupyter_notebook\\毕业设计\\dev\\end_to_end_dev_v0\\unsupervised\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, current_epoch, num_epochs, window_size, input_size)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;31m# Backward and optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at C:/w/1/s/tmp_conda_3.6_095855/conda/conda-bld/pytorch_1579082406639/work/aten/src\\THC/generic/THCTensorMath.cu:26"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "unsupervised_model.train(model, dataloader, criterion, optimizer, current_epoch=0, num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(model.state_dict(), model_dir + '/' + model_usl_name + '.pt')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\\data\\lstm\\dataset_official\\normal.csv: 100%|████████████████████████████████| 14177/14177 [00:01<00:00, 12425.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset_official\\normal.csv): 14177\n",
      "Number of seqs(.\\data\\lstm\\dataset_official\\normal.csv): 269570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\\data\\lstm\\dataset_official\\abnormal.csv: 100%|████████████████████████████████| 4123/4123 [00:00<00:00, 20713.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset_official\\abnormal.csv): 4123\n",
      "Number of seqs(.\\data\\lstm\\dataset_official\\abnormal.csv): 88410\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "batch_size = 20000\n",
    "test_normal_session, test_normal_dataset, normal_block = generate_predicted_data(\n",
    "    lstm_dataset + unsupervised_test_normal, window_size)\n",
    "normal_dataloader = DataLoader(test_normal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_abnormal_session, test_abnormal_dataset, abnormal_block = generate_predicted_data(\n",
    "    lstm_dataset + unsupervised_test_abnormal, window_size)\n",
    "abnormal_dataloader = DataLoader(test_abnormal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "batch_size = 20000\n",
    "test_normal_session, test_normal_dataset, normal_block = generate_predicted_data(\n",
    "    lstm_dataset + 'no_dup_normal.csv', window_size)\n",
    "normal_dataloader = DataLoader(test_normal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_abnormal_session, test_abnormal_dataset, abnormal_block = generate_predicted_data(\n",
    "    lstm_dataset + 'no_dup_abnormal.csv', window_size)\n",
    "abnormal_dataloader = DataLoader(test_abnormal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unsupervised.predictor as unsupervised_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 5it [00:26,  5.33s/it]\n"
     ]
    }
   ],
   "source": [
    "re = unsupervised_predictor.predict(model, abnormal_dataloader,test_abnormal_session,10, window_size,ts=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 14it [01:10,  5.03s/it]\n",
      "loading data: 5it [00:22,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 93.172s\n",
      "false positive (FP): 893, false negative (FN): 120, Precision: 81.761%, Recall: 97.089%, F1-measure: 88.768%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_normal_result, test_abnormal_result = unsupervised_predictor.count_metries(model, normal_dataloader, abnormal_dataloader,\n",
    "                                                        test_normal_session, test_abnormal_session,\n",
    "                                                        10, window_size,ts=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 14it [01:09,  4.95s/it]\n",
      "loading data: 5it [00:21,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 91.204s\n",
      "false positive (FP): 557, false negative (FN): 349, Precision: 87.139%, Recall: 91.535%, F1-measure: 89.283%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_normal_result, test_abnormal_result = unsupervised_predictor.count_metries(model, normal_dataloader, abnormal_dataloader,\n",
    "                                                        test_normal_session, test_abnormal_session,\n",
    "                                                        10, window_size,ts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 14it [01:22,  5.90s/it]\n",
      "loading data: 5it [00:22,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 105.094s\n",
      "false positive (FP): 1114, false negative (FN): 369, Precision: 77.116%, Recall: 91.050%, F1-measure: 83.506%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_normal_result, test_abnormal_result = unsupervised_predictor.count_metries(model, normal_dataloader, abnormal_dataloader,\n",
    "                                                        test_normal_session, test_abnormal_session,\n",
    "                                                        10, window_size,ts=0.000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsupervised_input.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\\data\\lstm\\dataset_official\\unsupervised_input.csv: 100%|███████████████████████| 4999/4999 [00:00<00:00, 5801.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset_official\\unsupervised_input.csv): 4999\n",
      "Number of seqs(.\\data\\lstm\\dataset_official\\unsupervised_input.csv): 93821\n"
     ]
    }
   ],
   "source": [
    "sessions, dataset, block_to_seqs = generate_predicted_data(lstm_dataset+predicted_input,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20000\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 5it [00:24,  4.97s/it]\n"
     ]
    }
   ],
   "source": [
    "normal_result = unsupervised_predictor.predict(model, dataloader,sessions,10, window_size,ts=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(result):\n",
    "    TN = result[:3000].count(False)\n",
    "    FN = result[3000:].count(False)\n",
    "    print('TN:{} FN:{}'.format(TN,FN))\n",
    "    print('Negative Precision:',TN/(TN+FN))\n",
    "    TP = result[3000:].count(True)\n",
    "    FP = result[:3000].count(True)\n",
    "    print('TP:{} FP:{}'.format(TP,FP))\n",
    "    print('Positive Precision:',TP/(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:2853 FN:31\n",
      "Negative Precision: 0.989251040221914\n",
      "TP:1968 FP:147\n",
      "Positive Precision: 0.9304964539007092\n"
     ]
    }
   ],
   "source": [
    "show_result(normal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 5it [00:24,  4.82s/it]\n"
     ]
    }
   ],
   "source": [
    "abnormal_result = unsupervised_predictor.predict(model, dataloader,sessions,10, window_size,ts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:2938 FN:156\n",
      "Negative Precision: 0.9495798319327731\n",
      "TP:1843 FP:62\n",
      "Positive Precision: 0.9674540682414698\n"
     ]
    }
   ],
   "source": [
    "show_result(abnormal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(lstm_dataset+predicted_normal_output,'w')\n",
    "f.write('EventSequence\\n')\n",
    "for i,label in enumerate(normal_result):\n",
    "    if label==False:\n",
    "        f.write('\"'+str(block_to_seqs[i][1])+'\"\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(lstm_dataset+predicted_abnormal_output,'w')\n",
    "f.write('EventSequence\\n')\n",
    "for i,label in enumerate(abnormal_result):\n",
    "    if label:\n",
    "        f.write('\"'+str(block_to_seqs[i][1])+'\"\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.bert_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_bert_cache('.\\\\data\\\\lstm\\\\dataset_official\\\\HDFS_templates.txt',\"./data/lstm/bert_official_cache.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsupervised_normal_output.csv'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_normal_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsupervised_abnormal_output.csv'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_abnormal_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 100%|████████████████████████████████████████████████████████████| 2884/2884 [00:00<00:00, 192137.06it/s]\n",
      "loading data: 100%|████████████████████████████████████████████████████████████| 1905/1905 [00:00<00:00, 236682.04it/s]\n",
      "normal:: 100%|█████████████████████████████████████████████████████████████████████| 2883/2883 [01:03<00:00, 45.61it/s]\n",
      "abnormal:: 100%|███████████████████████████████████████████████████████████████████| 1895/1895 [00:43<00:00, 44.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset_official\\): 4778\n",
      "Number of normal sessions: 2883\n",
      "Number of abnormal sessions: 1895\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset=generate_bert_data(lstm_dataset,predicted_normal_output,predicted_abnormal_output,\"./data/lstm/bert_official_cache.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervised.model as supervised_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = supervised_model.Model(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sl_name = 'type={}_version={}'.format('official_supervised','v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_dir + '/' + model_sl_name + '.pt'):\n",
    "    print('loading model {} success.'.format(model_sl_name))\n",
    "    model.load_state_dict(torch.load(model_dir + '/' + model_name + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], train_loss: 2.3085\n",
      "Epoch [2/30], train_loss: 0.6736\n",
      "Epoch [3/30], train_loss: 0.6589\n",
      "Epoch [4/30], train_loss: 0.6476\n",
      "Epoch [5/30], train_loss: 0.6379\n",
      "Epoch [6/30], train_loss: 0.6371\n",
      "Epoch [7/30], train_loss: 0.6232\n",
      "Epoch [8/30], train_loss: 0.6073\n",
      "Epoch [9/30], train_loss: 0.5388\n",
      "Epoch [10/30], train_loss: 0.5965\n",
      "Epoch [11/30], train_loss: 0.4843\n",
      "Epoch [12/30], train_loss: 0.3699\n",
      "Epoch [13/30], train_loss: 0.6199\n",
      "Epoch [14/30], train_loss: 0.5685\n",
      "Epoch [15/30], train_loss: 0.4054\n",
      "Epoch [16/30], train_loss: 0.3473\n",
      "Epoch [17/30], train_loss: 0.5635\n",
      "Epoch [18/30], train_loss: 0.6030\n",
      "Epoch [19/30], train_loss: 0.5710\n",
      "Epoch [20/30], train_loss: 0.5686\n",
      "Epoch [21/30], train_loss: 0.5673\n",
      "Epoch [22/30], train_loss: 0.5660\n",
      "Epoch [23/30], train_loss: 0.5618\n",
      "Epoch [24/30], train_loss: 0.5560\n",
      "Epoch [25/30], train_loss: 0.5156\n",
      "Epoch [26/30], train_loss: 0.4590\n",
      "Epoch [27/30], train_loss: 0.4268\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-57a6f06ef399>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msupervised_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\python_workspace\\jupyter_notebook\\毕业设计\\dev\\end_to_end_dev_v0\\supervised\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, current_epoch, num_epochs, input_size)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python_workspace\\jupyter_notebook\\毕业设计\\dev\\end_to_end_dev_v0\\supervised\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mh0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\cuda_pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 559\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "supervised_model.train(model,train_dataloader,criterion,optimizer,current_epoch=0,num_epochs=30,input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def accuracy(y_pred, y_true):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    pred = np.argmax(y_pred.cpu().numpy(),1)\n",
    "    for i,val in enumerate(pred):\n",
    "        if val == 0:\n",
    "            if y_true[i]==0:\n",
    "                TN +=1\n",
    "            else:\n",
    "                FN +=1\n",
    "        else:\n",
    "            if y_true[i]==1:\n",
    "                TP+=1\n",
    "            else:\n",
    "                FP+=1\n",
    "    return TP,TN,FP,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model,data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        for step, (seq, label) in enumerate(data):\n",
    "            seq = seq.clone().detach().view(-1, seq.shape[1], input_size).to(device)\n",
    "            test_output = model(seq.to(device))\n",
    "            if step == 0:\n",
    "                output = test_output\n",
    "                labels = label\n",
    "            else:\n",
    "                labels = torch.cat([labels, label], 0)\n",
    "                output = torch.cat([output, test_output], 0)\n",
    "            epoch_loss += criterion(test_output, label.to(device)).data\n",
    "        TP,TN,FP,FN = accuracy(output, labels)\n",
    "        epoch_accuracy = (TP+TN)/(FP+FN+TP+TN)\n",
    "        epoch_loss = epoch_loss / len(data)\n",
    "        print('TN:{} FN:{}'.format(TN,FN))\n",
    "        print('Negative Precision:',round(TN/(TN+FN),3))\n",
    "        print('TP:{} FP:{}'.format(TP,FP))\n",
    "        print('Positive Precision:',round(TP/(TP+FP),3))\n",
    "        print('loss: ', round(epoch_loss.item(), 3), 'accuracy: ', round(epoch_accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:1679 FN:33\n",
      "Negative Precision: 0.981\n",
      "TP:1108 FP:46\n",
      "Positive Precision: 0.96\n",
      "loss:  0.11 accuracy:  0.972\n"
     ]
    }
   ],
   "source": [
    "predict_result(model,train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:1137 FN:32\n",
      "Negative Precision: 0.973\n",
      "TP:722 FP:21\n",
      "Positive Precision: 0.972\n",
      "loss:  0.106 accuracy:  0.972\n"
     ]
    }
   ],
   "source": [
    "predict_result(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\data\\\\lstm\\\\dataset_official\\\\'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_input_normal = 'supervised_input_normal.csv'\n",
    "supervised_input_abnormal = 'supervised_input_abnormal.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 100%|█████████████████████████████████████████████████████████████| 4999/4999 [00:00<00:00, 11874.96it/s]\n",
      "loading data: 100%|████████████████████████████████████████████████████████████| 2123/2123 [00:00<00:00, 235943.49it/s]\n",
      "normal:: 100%|█████████████████████████████████████████████████████████████████████| 4994/4994 [01:52<00:00, 44.36it/s]\n",
      "abnormal:: 100%|███████████████████████████████████████████████████████████████████| 2117/2117 [00:45<00:00, 46.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(.\\data\\lstm\\dataset_official\\): 7111\n",
      "Number of normal sessions: 4994\n",
      "Number of abnormal sessions: 2117\n"
     ]
    }
   ],
   "source": [
    "test_dataset1,test_dataset2 =generate_bert_data(lstm_dataset,supervised_input_normal,supervised_input_abnormal,\"./data/lstm/bert_official_cache.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:100][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1270)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(test_dataset1[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader1 = DataLoader(test_dataset1, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader2 = DataLoader(test_dataset2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:2790 FN:40\n",
      "Negative Precision: 0.986\n",
      "TP:1229 FP:207\n",
      "Positive Precision: 0.856\n",
      "loss:  0.196 accuracy:  0.942\n"
     ]
    }
   ],
   "source": [
    "predict_result(model,test_dataloader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:1898 FN:16\n",
      "Negative Precision: 0.992\n",
      "TP:832 FP:99\n",
      "Positive Precision: 0.894\n",
      "loss:  0.147 accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "predict_result(model,test_dataloader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised.wf_constructor import workflow_constructor,draw_wf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(model.state_dict(), model_dir + '/' + model_usl_name + '.pt')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-85f05b3ef088>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkflow_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "wf = workflow_constructor(model,input_size=1)\n",
    "wf.generate_seq([0],1,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.workflow_construction([0],{30})\n",
    "draw_wf(wf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('cuda_pytorch': conda)",
   "language": "python",
   "name": "python36764bitcudapytorchconda3e33319a1fef4dc990a9d2f171216946"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
