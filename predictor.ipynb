{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 32\n",
    "batch_size = 20000\n",
    "input_size = 1\n",
    "model_dir = 'model'\n",
    "window_size = 10\n",
    "num_layers = 2\n",
    "hidden_size = 64\n",
    "file_dir = 'data_official'\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_keys)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, :, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(name,window_size=10):\n",
    "    hdfs = set()\n",
    "    # hdfs = []\n",
    "    with open(name, 'r') as f:\n",
    "        for ln in f.readlines():\n",
    "            ln = [0]+list(map(lambda n: n, map(int, ln.strip().split())))+[30]\n",
    "            ln = ln + [-1] * (window_size + 1 - len(ln))\n",
    "            hdfs.add(tuple(ln))\n",
    "            # hdfs.append(tuple(ln))\n",
    "    session_to_seq = []\n",
    "    seqs = []\n",
    "    labels = []\n",
    "    seq_count = 0\n",
    "    for line in tqdm(hdfs, \"normal:\"):\n",
    "        session = []\n",
    "        for i in range(len(line) - window_size):\n",
    "            seq = line[i:i + window_size]\n",
    "            label = line[i + window_size]\n",
    "            seqs.append(seq)\n",
    "            session.append(seq_count)\n",
    "            labels.append(label)\n",
    "            seq_count += 1\n",
    "        session_to_seq.append(session)\n",
    "    print('Number of sessions({}): {}'.format(name, len(session_to_seq)))\n",
    "    print('Number of seqs({}): {}'.format(name, len(seqs)))\n",
    "    dataset = TensorDataset(torch.tensor(seqs, dtype=torch.float), torch.tensor(labels))\n",
    "\n",
    "    return session_to_seq, dataset, seqs,labels\n",
    "\n",
    "# fast predict\n",
    "def fast_predict(model,normal_dataloader,abnormal_dataloader,num_candidates=5,window_size=10):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    # Test the model\n",
    "    start_time = time.time()\n",
    "    test_normal_result = []\n",
    "    test_abnormal_result = []\n",
    "    with torch.no_grad():\n",
    "        with torch.no_grad():\n",
    "            for step, (seq, labels) in tqdm(enumerate(normal_dataloader), desc='normal'):\n",
    "                seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "                output = model(seq).cpu()\n",
    "\n",
    "                predicted = torch.argsort(output[:,-1,:], 1)[:,-num_candidates:]\n",
    "                for i, label in enumerate(labels):\n",
    "                    if label not in predicted[i]:\n",
    "                        test_normal_result.append(True)\n",
    "                    else:\n",
    "                        test_normal_result.append(False)\n",
    "    for session in test_normal_session:\n",
    "        for seq_id in session:\n",
    "            if test_normal_result[seq_id] == True:\n",
    "                FP += 1\n",
    "                break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (seq, labels) in tqdm(enumerate(abnormal_dataloader), desc='abnormal'):\n",
    "            seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "            output = model(seq).cpu()\n",
    "\n",
    "            predicted = torch.argsort(output[:,-1,:], 1)[:,-num_candidates:]\n",
    "            for i, label in enumerate(labels):\n",
    "                if label not in predicted[i]:\n",
    "                    test_abnormal_result.append(True)\n",
    "                else:\n",
    "                    test_abnormal_result.append(False)\n",
    "        for session in test_abnormal_session:\n",
    "            for seq_id in session:\n",
    "                if test_abnormal_result[seq_id] == True:\n",
    "                    TP += 1\n",
    "                    break\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
    "    # Compute precision, recall and F1-measure\n",
    "    FN = len(test_abnormal_session) - TP\n",
    "    P = 100 * TP / (TP + FP)\n",
    "    R = 100 * TP / (TP + FN)\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
    "    print('Finished Predicting')\n",
    "    return test_normal_result,test_abnormal_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(name,window_size=10):\n",
    "    hdfs = set()\n",
    "    # hdfs = []\n",
    "    with open(name, 'r') as f:\n",
    "        for ln in f.readlines():\n",
    "            ln = [0]+list(map(lambda n: n, map(int, ln.strip().split())))+[30]\n",
    "            ln = ln + [-1] * (window_size + 1 - len(ln))\n",
    "            hdfs.add(tuple(ln))\n",
    "            # hdfs.append(tuple(ln))\n",
    "    session_to_seq = []\n",
    "    seqs = []\n",
    "    labels = []\n",
    "    seq_count = 0\n",
    "    for line in tqdm(hdfs, \"normal:\"):\n",
    "        session = []\n",
    "        for i in range(len(line) - window_size):\n",
    "            seq = line[i:i + window_size]\n",
    "            label = line[i + window_size]\n",
    "            seqs.append(seq)\n",
    "            session.append(seq_count)\n",
    "            labels.append(label)\n",
    "            seq_count += 1\n",
    "        session_to_seq.append(session)\n",
    "    print('Number of sessions({}): {}'.format(name, len(session_to_seq)))\n",
    "    print('Number of seqs({}): {}'.format(name, len(seqs)))\n",
    "    dataset = TensorDataset(torch.tensor(seqs, dtype=torch.float), torch.tensor(labels))\n",
    "\n",
    "    return session_to_seq, dataset, seqs,labels\n",
    "\n",
    "# fast predict\n",
    "def fast_predict(model,normal_dataloader,abnormal_dataloader,num_candidates=5,window_size=10,ts=0.001):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    # Test the model\n",
    "    start_time = time.time()\n",
    "    test_normal_result = []\n",
    "    test_abnormal_result = []\n",
    "    with torch.no_grad():\n",
    "        with torch.no_grad():\n",
    "            for step, (seq, labels) in tqdm(enumerate(normal_dataloader), desc='normal'):\n",
    "                seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "                output = model(seq).cpu()\n",
    "                output = output[:,-1,:]\n",
    "                prob = softmax(output)\n",
    "                predicted = torch.argsort(output, 1)[:,-num_candidates:]\n",
    "                for i, label in enumerate(labels):\n",
    "                    if label not in predicted[i] or prob[i][label]<ts:\n",
    "                        test_normal_result.append(True)\n",
    "                    else:\n",
    "                        test_normal_result.append(False)\n",
    "    for session in test_normal_session:\n",
    "        for seq_id in session:\n",
    "            if test_normal_result[seq_id] == True:\n",
    "                FP += 1\n",
    "                break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (seq, labels) in tqdm(enumerate(abnormal_dataloader), desc='abnormal'):\n",
    "            seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
    "            output = model(seq).cpu()\n",
    "            output = output[:,-1,:]\n",
    "            prob = softmax(output)\n",
    "            predicted = torch.argsort(output, 1)[:,-num_candidates:]\n",
    "#             predicted = torch.argsort(output[:,-1,:], 1)[:,-num_candidates:]\n",
    "            for i, label in enumerate(labels):\n",
    "                if label not in predicted[i] or prob[i][label]<ts:\n",
    "                    test_abnormal_result.append(True)\n",
    "                else:\n",
    "                    test_abnormal_result.append(False)\n",
    "        for session in test_abnormal_session:\n",
    "            for seq_id in session:\n",
    "                if test_abnormal_result[seq_id] == True:\n",
    "                    TP += 1\n",
    "                    break\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
    "    # Compute precision, recall and F1-measure\n",
    "    FN = len(test_abnormal_session) - TP\n",
    "    P = 100 * TP / (TP + FP)\n",
    "    R = 100 * TP / (TP + FN)\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
    "    print('Finished Predicting')\n",
    "    return test_normal_result,test_abnormal_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_result(name,sessions,seqs,results): \n",
    "    with open(name+'.txt','w') as f:\n",
    "        for session in sessions:\n",
    "            pos = False\n",
    "            seq = -1\n",
    "            for seq_id in session:\n",
    "                if results[seq_id]==True:\n",
    "                    seq = seq_id\n",
    "                    break\n",
    "            if seq==-1 and name=='FN':\n",
    "                session_events = []\n",
    "                session_events.extend(seqs[session[0]][1:])\n",
    "                for seq_id in session[1:]:\n",
    "                    session_events.append(seqs[seq_id][-1])\n",
    "                f.write(' '.join(list(map(str,session_events)))+'\\n')\n",
    "            elif seq!=-1 and name=='FP':\n",
    "                session_events = []\n",
    "                session_events.extend(seqs[session[0]][1:])\n",
    "                for seq_id in session[1:]:\n",
    "                    session_events.append(seqs[seq_id][-1])\n",
    "                f.write(' '.join(list(map(str,session_events)))+'\\n')\n",
    "                f.write(' '.join(list(map(str,seqs[seq])))+'\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "model_name = 'data_dir={}_version={}'.format('data_official', 'v0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_dir=data_dev_version=v0.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name ='add_padding_batch_size=2048_epoch=300_window_size=10'\n",
    "model_name = 'data_dir={}_version={}'.format('data_dev', 'v0.0')\n",
    "file_dir = 'data_dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lstm): LSTM(1, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_dir + '/' + model_name + '.pt'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal:: 100%|████████████████████████████████████████████████████████████████| 14195/14195 [00:00<00:00, 42500.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(data_dev/hdfs_test_normal): 14195\n",
      "Number of seqs(data_dev/hdfs_test_normal): 269979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal:: 100%|██████████████████████████████████████████████████████████████████| 4121/4121 [00:00<00:00, 41628.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions(data_dev/hdfs_test_abnormal): 4121\n",
      "Number of seqs(data_dev/hdfs_test_abnormal): 88562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20000\n",
    "window_size = 10\n",
    "test_normal_session, test_normal_dataset, test_normal_seq, test_normal_label = generate_test_data(\n",
    "    file_dir+'/hdfs_test_normal', window_size)\n",
    "normal_dataloader = DataLoader(test_normal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_abnormal_session, test_abnormal_dataset, test_abnormal_seq, test_abnormal_label = generate_test_data(\n",
    "    file_dir+'/hdfs_test_abnormal', window_size)\n",
    "abnormal_dataloader = DataLoader(test_abnormal_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normal: 14it [00:51,  3.68s/it]\n",
      "abnormal: 5it [00:14,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 66.172s\n",
      "false positive (FP): 918, false negative (FN): 151, Precision: 81.219%, Recall: 96.336%, F1-measure: 88.134%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_normal_result, test_abnormal_result = fast_predict(model, normal_dataloader, abnormal_dataloader, 10,\n",
    "                                                        window_size,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 2, 1, 3, 4, 3, 4, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_normal_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "normal: 0it [00:00, ?it/s]\u001b[A\n",
      "normal: 1it [00:05,  5.30s/it]\u001b[A\n",
      "normal: 2it [00:10,  5.40s/it]\u001b[A\n",
      "normal: 3it [00:15,  5.29s/it]\u001b[A\n",
      "normal: 4it [00:20,  5.14s/it]\u001b[A\n",
      "normal: 5it [00:25,  5.05s/it]\u001b[A\n",
      "normal: 6it [00:30,  4.93s/it]\u001b[A\n",
      "normal: 7it [00:34,  4.87s/it]\u001b[A\n",
      "normal: 8it [00:40,  5.02s/it]\u001b[A\n",
      "normal: 9it [00:45,  5.13s/it]\u001b[A\n",
      "normal: 10it [00:51,  5.26s/it]\u001b[A\n",
      "normal: 11it [00:56,  5.22s/it]\u001b[A\n",
      "normal: 12it [01:01,  5.32s/it]\u001b[A\n",
      "normal: 13it [01:07,  5.35s/it]\u001b[A\n",
      "normal: 14it [01:10,  5.02s/it]\u001b[A\n",
      "\n",
      "abnormal: 0it [00:00, ?it/s]\u001b[A\n",
      "abnormal: 1it [00:04,  4.95s/it]\u001b[A\n",
      "abnormal: 2it [00:09,  4.83s/it]\u001b[A\n",
      "abnormal: 3it [00:14,  4.87s/it]\u001b[A\n",
      "abnormal: 4it [00:19,  4.86s/it]\u001b[A\n",
      "abnormal: 5it [00:21,  4.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 91.692s\n",
      "false positive (FP): 389, false negative (FN): 1581, Precision: 86.728%, Recall: 61.654%, F1-measure: 72.073%\n",
      "Finished Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_normal_result, test_abnormal_result = fast_predict(model, normal_dataloader, abnormal_dataloader, 10,\n",
    "                                                        window_size,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name,sessions,seqs,results\n",
    "name = 'FN'\n",
    "sessions = test_abnormal_session.copy()\n",
    "seqs = test_abnormal_seq.copy()\n",
    "results = test_abnormal_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name,sessions,seqs,results\n",
    "name = 'TP'\n",
    "sessions = test_abnormal_session.copy()\n",
    "seqs = test_abnormal_seq.copy()\n",
    "results = test_abnormal_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name,sessions,seqs,results\n",
    "name = 'FP'\n",
    "sessions = test_normal_session.copy()\n",
    "seqs = test_normal_seq.copy()\n",
    "results = test_normal_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(name+'.txt','w') as f:\n",
    "    for i,session in enumerate(sessions):\n",
    "        pos = False\n",
    "        seq = -1\n",
    "        for seq_id in session:\n",
    "            if results[seq_id]==True:\n",
    "                seq = seq_id\n",
    "                break\n",
    "        if seq==-1 and ('FN' in name or name=='TN' in name):\n",
    "            session_events = []\n",
    "            session_events.extend(seqs[session[0]][1:])\n",
    "            for seq_id in session[1:]:\n",
    "                session_events.append(seqs[seq_id][-1])\n",
    "            f.write(' '.join(list(map(str,session_events)))+'\\n')\n",
    "        elif seq!=-1 and ('FP' in name or 'TP' in name):\n",
    "            f.write(str(i)+' ')\n",
    "            session_events = []\n",
    "            session_events.extend(seqs[session[0]][1:])\n",
    "            for seq_id in session[1:]:\n",
    "                session_events.append(seqs[seq_id][-1])\n",
    "            f.write(' '.join(list(map(str,session_events)))+'\\n')\n",
    "            f.write(' '.join(list(map(str,seqs[seq])))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('cuda_pytorch': conda)",
   "language": "python",
   "name": "python36764bitcudapytorchconda3e33319a1fef4dc990a9d2f171216946"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
